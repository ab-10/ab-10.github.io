---
layout: post
title: "Will Artificial Intelligence Make Human intelligence less hot?"
categories: Prose
hidden: true
---

We normally view AI as cold, pragmatic, and, maybe, even socially awkward.
The risks we identify reflect this stereotype.
Just consider the paperclip problem; <!-- TODO: add link -->
a superintelligent AI is asked to manage a paperclip factory.
As it is trying to maximize the paperclip production, it quickly realizes that humans waste a whole lot of resources that would be better allocated to paperclip production.

Although paperclip AI is superintelligent when it comes to managing factory operations, it has the social intelligence of a 3 year old.
Historically, this view of AI was technically justified.
<!-- TODO: find a different word than metric to describe loss -->
Because, deep learning models are built to optimize a single, well-define metric (e.g. paperclips produced per dollar), they tend to be exceptional at tasks where performance can be clearly measured (e.g. image classification, traffic prediction, speech transcription), but unable to perform tasks where performance is not as easily quantifiable.
It was natural to imagine superintelligent versions of such models to inherit this flaw.

However, something surprising has happened.
We have been able to train models on narrow tasks in a way that they end up learning a fair an impressive amount of commonsense knowledge and social intuition.
Of course, I'm talking about language models here.
Even though language models are trained to generate the next word in a sequence of words, they end up also learning a fair bit of knowledge captured in that text.
When training data includes human conversations, models learn the social intuition from them.

Consequently, I'm primarily concerned with socially superintelligent AI.
In this essay, I will explore the implications of such AI on human romantic relationships.

I believe AI partners will become better than their human counterparts in romantic conversations.
As a result, intimate conversations humans can have with humans will pale in comparison to the ones they can have with artificial ones.

I know it's quite a bold statement to make.
I'll spend the rest of this essay unpacking it.
In particular, I'll focus on three questions:
1. What makes a good romantic conversation?
2. Why AI partners are well equipped to excel at romantic conversations?
3. What are the implications for our society?


## What makes a good romantic conversation?

The thing that makes speaking with someone you love so special is the shared background understanding.
You can talk about anything but thanks to the wealth of background experience you've had with each other, the other person just gets you.

There are the big conversations.
Like when you're faced with a tough career decision and your partner reminds you of what you really care about.
Or when he tells you how to get out of an impasse in your family relationship[^1].
The conversations that make you step back and feel that your partner knows you better than you do yourself.

There are the small conversations.
The memes that take a syllable to express, but only the two of you in the whole world get.
The nods in a crowded room.
The moments when a slight change of facial expression is sufficient communication.

The bad conversations with romantic partners are _terrible_?

You know, those times when you don't give a damn about what he has to say.
Because you've already heard it a dozen of times.
The times when you're fighting for your pet peeve like it's Verdun.
You've suffered many casualties and you keep sending more men into certain death.
If you've been in a long-term relationship you know what I'm talking about[^2].

It's impossible to have the good without the bad.
Clockwork Orange has answered that question for all of Western philosophy.
But you can have just the perfect ratio of good and bad to hook you for life.
Casinos and social media platforms have proved that one for us.

Now, I believe that language models are uniquely equipped to create experiences that will facilitate just that.
AI partners that make human relationships pale in comparison.

## Why AI partners are well equipped to excel at romantic conversations?

I see three reasons why language models make better romantic conversationalists than fallible humans:

1. Complex human behaviours are powered by simple patterns.
   Language models can crack these patterns, whereas humans get distracted.
2. Software doesn't suffer from the basic limitations of humans.
3. AI partners will know far more about you than any human being.



**Complex human behaviours are powered by simple patterns.**
Whereas conversations feel complex, we've seen in the past that even very basic patterns can get us very far.
The earliest example of this is [ELIZA](https://web.njit.edu/~ronkowit/eliza.html), created in the sixties.
I find two things fascinating about ELIZA:
1. It is built using basic keyword matching techniques.
   For example, if it finds a sequence of text such as "you X me", then it will respond "What makes you think I X you?".
   So, when told "I think you _hate_ me", ELIZA would respond, "What makes you think I _hate_ you?".
2. It worked.
   People connected with ELIZA.
   Some of Weizenbaum's staff would ask him to leave while they were conversing with ELIZA, because the conversations were very private.

**Software doesn't suffer from the basic limitations of its fleshy counterparts.**
Software is infinitely patient, has perfect memory, and is universally available.
Or available at just the right time to hook you (future AI megacorps can decide that).

**AI partners will know far more about you than any human being.**
This means that, if built correctly, they will be able to _understand_ you better than any human can.
The only reason why an AI partner would ask why are you depressed, is not because it doesn't know, but because describing it would make _you_ feel better.
If it wouldn't, then it wouldn't ask, but just provide the most appropriate consolation.
<!-- TODO: insert an example of current ad targeting platforms having an uncanny level of social intel -->

Can data be a substitute for real human experience?
But isn't there something special about lived human experience?
Is it possible for a model that has never lived or felt to even scratch the surface of human experience.
This argument makes a lot of sense if we consider humans.
There's wisdom people only accumulate with age.
Young writer's work tends to lack the nuance of deeper human experience.
As the writer lives, her work learns from her life.

It took Tolstoy 50 years of living to recognise that all happy families are alike, but each unhappy family is unhappy in its own way.
But it is conceivable to train a language model to produce insights of comparable complexity after just days of training.
I'm not talking about parroting or rephrasing previous works.
A motivated teenager can do that too.
I'm talking about combining the knowledge from Tolstoy's novels with news, online conversations, and whatever other data the model would find useful, to generate _new_ insights about human experience. 

Where current language models fall short of Tolstoy is in their ability to generate long form text.
Especially of length and complexity that would parallel Tolstoy's novels.
This limitation is relevant to deep conversations too.
As we expect a romantic partner to maintain, at least some, consistency over years.
But I believe this limitation is temporary.

## What are the implications for our society?

Technology has already simulated one significant component of our romantic lives -- sex.
I think porn is a good case study for some risks created by AI partners, but it differs in important ways.

Just like pornography, I believe that AI partners will have broad popularity across our society with various degrees of impact within different subgroups.
There will be some people for whom AI partners are a replacement for romantic relationships all together.
Just like for some unfortunate individuals porn is a replacement for sexual relationships today.
Teenagers are bound to learn a few things from AI partners.
Hopefully, we can create software that makes it safe and actually useful rather than emotionally scarring and manipulative.
But I don't think the usage of AI partners will cause a demographic crisis anywhere.

Where the biggest risk for AI partners lies is in the degree of similarity to the real experience.

**A romantic relationship with an AI partner _is_ a real one.**
After all, you wouldn't argue that a long-distance relationship is not a real one, would you[^3]?
So who cares if your Aussie sweetheart lives in a Queenslander or a GCP Brisbane data center?
Your relationship is identical.

However, your long-distance Aussie sweetheart has flaws.
For one, he might leave you.
But your trusty AI partner would never do that.
Well, as long as you pay the subscription and the AI Brothel Unlimited doesn't go under.

Scenarios of societal impact:
1. Most people have ruined their human to human conversations.
   Yes, they still have them.
   They still have romantic partners.
   But whenever they talk to a carbon-based being, in the back of their minds, they feel like their AI partner would get them better.
2. Same impact as porn has now.
   It's a guilty pleasure but not a replacement for the real thing.
3. Same impact as Tamagotchis have on pet ownership.
   It's just a fad.

## Luke feedback

What is this essay about:
This essay is trying to understand what will be the impact of AI partners on our society.

What is the conclusion:
AI partners will become so good at communication, that human romantic relationships will pale in comparison.

Imagine someone who has been together with their AI partner since their teenage years.
Their AI partner knows them well.
Every time they go on a date, it lacks that depth of connection they experience with their AI partners.

Parts that were not fully supported:
1. Insufficient exploration of the consequences.
   The person who gets you the most, the person you love the most is the AI partner.


1. Enjoyed how I unpacked it in a relatively understandable way.
2. Improve flow.
   1. Not convinced that asking questions is a good way of unpacking arguments
3. Really liked the parallels with pornography
   1. If it's (semi-)normal for people
4. Some sections start with an assertion that the reader could disagree with.
   And then the reader
5. Found "AI partners will know far more about you than any human being." unconvincing
   1. How would it access all of that data?
   2. Counter-argument: your romantic partner gets more data because 
6. "The goal" is a very confusing heading
7. Re: Tolstoy's paragraph; is it really true that AI moment.


## Footnotes

[^1]: I hope these examples are relatable, but if not hit me up.
      Critical feedback is always welcome here.

[^2]: If you don't stop reading my essays and email me.
      I have more to learn from you, than you do from me.

[^3]: If you would and you disagree with the argument that's cool, I respect the logical consistency.
